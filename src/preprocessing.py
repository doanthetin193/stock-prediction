"""
Module tiá»n xá»­ lÃ½ dá»¯ liá»‡u cho cÃ¡c models.
- ThÃªm Technical Indicators (SMA, EMA, RSI, MACD)
- Chuáº©n bá»‹ data cho DL (LSTM/GRU), ML (XGBoost), Prophet, ARIMA
"""
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

import os, sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import SEQUENCE_LENGTH, TEST_RATIO, FEATURE_COLUMNS, TARGET_COLUMN


# ============================================================
# Technical Indicators
# ============================================================

def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """
    ThÃªm cÃ¡c chá»‰ bÃ¡o ká»¹ thuáº­t vÃ o DataFrame.

    ThÃªm: SMA_10, SMA_20, SMA_50, EMA_12, EMA_26, RSI_14,
          MACD, MACD_Signal, Price_Change, Price_Change_Pct
    """
    df = df.copy()

    # --- Simple Moving Average ---
    df['sma_10'] = df['close'].rolling(window=10).mean()
    df['sma_20'] = df['close'].rolling(window=20).mean()
    df['sma_50'] = df['close'].rolling(window=50).mean()

    # --- Exponential Moving Average ---
    df['ema_12'] = df['close'].ewm(span=12, adjust=False).mean()
    df['ema_26'] = df['close'].ewm(span=26, adjust=False).mean()

    # --- RSI (Relative Strength Index) ---
    delta = df['close'].diff()
    gain = delta.where(delta > 0, 0).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi_14'] = 100 - (100 / (1 + rs))

    # --- MACD ---
    df['macd'] = df['ema_12'] - df['ema_26']
    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()

    # --- Price Change ---
    df['price_change'] = df['close'].diff()
    df['price_change_pct'] = df['close'].pct_change() * 100

    # --- Volume Change ---
    df['volume_change_pct'] = df['volume'].pct_change() * 100

    # Loáº¡i bá» NaN tá»« rolling
    df.dropna(inplace=True)
    df.reset_index(drop=True, inplace=True)

    return df


# ============================================================
# Data cho Deep Learning (LSTM / GRU)
# ============================================================

def create_sequences(data: np.ndarray, seq_length: int = SEQUENCE_LENGTH):
    """
    Táº¡o sequences cho LSTM/GRU.

    Args:
        data: Máº£ng 2D (samples, features) Ä‘Ã£ Ä‘Æ°á»£c scale
        seq_length: Sá»‘ time steps Ä‘á»ƒ lookback

    Returns:
        X: shape (samples, seq_length, features)
        y: shape (samples,) â€” giÃ¡ trá»‹ close táº¡i time step tiáº¿p theo
    """
    X, y = [], []
    for i in range(seq_length, len(data)):
        X.append(data[i - seq_length:i])     # seq_length ngÃ y trÆ°á»›c
        y.append(data[i, 0])                 # Close á»Ÿ vá»‹ trÃ­ 0 (sau reorder)
    return np.array(X), np.array(y)


def prepare_data_dl(df: pd.DataFrame, seq_length: int = SEQUENCE_LENGTH,
                    test_ratio: float = TEST_RATIO):
    """
    Chuáº©n bá»‹ dá»¯ liá»‡u cho LSTM/GRU.

    Returns:
        X_train, X_test, y_train, y_test, scaler
    """
    # Chá»n features â€” Ä‘áº·t close lÃªn Ä‘áº§u
    feature_cols = ['close', 'open', 'high', 'low', 'volume']
    # ThÃªm indicators náº¿u cÃ³
    extra_cols = ['sma_10', 'sma_20', 'ema_12', 'rsi_14', 'macd']
    for col in extra_cols:
        if col in df.columns:
            feature_cols.append(col)

    data = df[feature_cols].values

    # Scale dá»¯ liá»‡u vá» [0, 1]
    scaler = MinMaxScaler(feature_range=(0, 1))
    data_scaled = scaler.fit_transform(data)

    # Táº¡o sequences
    X, y = create_sequences(data_scaled, seq_length)

    # Chia train / test
    split = int(len(X) * (1 - test_ratio))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    print(f"  ğŸ“Š DL Data: X_train={X_train.shape}, X_test={X_test.shape}")
    print(f"     Features: {feature_cols}")

    return X_train, X_test, y_train, y_test, scaler


# ============================================================
# Data cho Machine Learning (XGBoost)
# ============================================================

def prepare_data_ml(df: pd.DataFrame, test_ratio: float = TEST_RATIO):
    """
    Chuáº©n bá»‹ dá»¯ liá»‡u cho XGBoost.
    DÃ¹ng technical indicators lÃ m features, close ngÃ y tiáº¿p theo lÃ m target.

    Returns:
        X_train, X_test, y_train, y_test, feature_names
    """
    df = df.copy()

    # Features cho ML
    feature_cols = ['open', 'high', 'low', 'close', 'volume']
    extra_cols = ['sma_10', 'sma_20', 'sma_50', 'ema_12', 'ema_26',
                  'rsi_14', 'macd', 'macd_signal', 'price_change',
                  'price_change_pct', 'volume_change_pct']
    for col in extra_cols:
        if col in df.columns:
            feature_cols.append(col)

    # Target: giÃ¡ close ngÃ y tiáº¿p theo
    df['target'] = df['close'].shift(-1)
    df.dropna(inplace=True)

    X = df[feature_cols].values
    y = df['target'].values

    # Chia train / test
    split = int(len(X) * (1 - test_ratio))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    print(f"  ğŸ“Š ML Data: X_train={X_train.shape}, X_test={X_test.shape}")
    print(f"     Features ({len(feature_cols)}): {feature_cols}")

    return X_train, X_test, y_train, y_test, feature_cols


# ============================================================
# Data cho Prophet
# ============================================================

def prepare_data_prophet(df: pd.DataFrame, test_ratio: float = TEST_RATIO):
    """
    Chuáº©n bá»‹ dá»¯ liá»‡u cho Prophet.
    Prophet yÃªu cáº§u cá»™t 'ds' (datetime) vÃ  'y' (giÃ¡ trá»‹).

    Returns:
        train_df, test_df
    """
    prophet_df = pd.DataFrame({
        'ds': df['time'],
        'y': df['close']
    })

    split = int(len(prophet_df) * (1 - test_ratio))
    train_df = prophet_df[:split].copy()
    test_df = prophet_df[split:].copy()

    print(f"  ğŸ“Š Prophet Data: train={len(train_df)}, test={len(test_df)}")

    return train_df, test_df


# ============================================================
# Data cho ARIMA
# ============================================================

def prepare_data_arima(df: pd.DataFrame, test_ratio: float = TEST_RATIO):
    """
    Chuáº©n bá»‹ dá»¯ liá»‡u cho ARIMA.
    ARIMA cáº§n chuá»—i thá»i gian Ä‘Æ¡n biáº¿n (close price).

    Returns:
        train_series, test_series
    """
    close_series = df.set_index('time')['close']

    split = int(len(close_series) * (1 - test_ratio))
    train_series = close_series[:split]
    test_series = close_series[split:]

    print(f"  ğŸ“Š ARIMA Data: train={len(train_series)}, test={len(test_series)}")

    return train_series, test_series


# ============================================================
# Inverse transform â€” chuyá»ƒn tá»« giÃ¡ trá»‹ scale vá» giÃ¡ trá»‹ thá»±c
# ============================================================

def inverse_transform_predictions(predictions: np.ndarray, scaler: MinMaxScaler,
                                   n_features: int) -> np.ndarray:
    """
    Chuyá»ƒn predictions tá»« scaled vá» giÃ¡ trá»‹ thá»±c.
    VÃ¬ scaler Ä‘Æ°á»£c fit trÃªn nhiá»u features, cáº§n padding.

    Args:
        predictions: máº£ng 1D predictions Ä‘Ã£ scale
        scaler: MinMaxScaler Ä‘Ã£ fit
        n_features: sá»‘ features ban Ä‘áº§u

    Returns:
        Máº£ng 1D giÃ¡ trá»‹ thá»±c
    """
    # Táº¡o máº£ng dummy vá»›i n_features cá»™t, Ä‘áº·t predictions vÃ o cá»™t 0 (close)
    dummy = np.zeros((len(predictions), n_features))
    dummy[:, 0] = predictions
    inversed = scaler.inverse_transform(dummy)
    return inversed[:, 0]
